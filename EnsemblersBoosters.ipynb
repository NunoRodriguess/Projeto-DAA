{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85d5af3c-b360-40ac-b1ca-b040430bede1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import imblearn\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4957abd-3351-470e-b871-78b5eec613fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 305 entries, 0 to 304\n",
      "Columns: 2162 entries, diagnostics_Image-original_Dimensionality to Transition\n",
      "dtypes: float64(2161), object(1)\n",
      "memory usage: 5.0+ MB\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "radi = pd.read_csv(\"sbsppdaa24/train_radiomics_hipocamp.csv\")\n",
    "\n",
    "# Drop unique identifier columns\n",
    "radi.drop(columns=[\"Mask\", \"ID\", \"Image\"], inplace=True)\n",
    "\n",
    "# Drop non-numeric columns except for 'Transition'\n",
    "columns_to_drop = [col for col in radi.columns if radi[col].dtype == 'object' and col != 'Transition']\n",
    "radi.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "# Apply MinMax scaling to columns\n",
    "float_cols = radi.select_dtypes(include=['float','int']).columns\n",
    "scaler = MinMaxScaler()\n",
    "radi[float_cols] = scaler.fit_transform(radi[float_cols])\n",
    "\n",
    "# Intantiate Report\n",
    "classification_reports = {}\n",
    "\n",
    "# Check final dataset\n",
    "radi.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "764516de-dd90-4e8f-8d0a-e508e0b9dfeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV,StratifiedKFold\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "\n",
    "# Estado vai ser comum para todos os modelos, \n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=2025)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e07871-dd1b-489a-aae5-ee509069e8f1",
   "metadata": {},
   "source": [
    "## Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27898429-69f0-4ccd-a29f-e9005376da27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Bagging Model Parameters: {'n_estimators': 1000}\n",
      "Bagging Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       AD-AD       0.56      0.36      0.43        14\n",
      "       CN-CN       0.51      0.69      0.59        26\n",
      "      CN-MCI       0.00      0.00      0.00         1\n",
      "      MCI-AD       0.32      0.43      0.36        14\n",
      "     MCI-MCI       0.21      0.14      0.17        22\n",
      "\n",
      "    accuracy                           0.42        77\n",
      "   macro avg       0.32      0.32      0.31        77\n",
      "weighted avg       0.39      0.42      0.39        77\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nunorodrigues/miniconda3/envs/myenv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/nunorodrigues/miniconda3/envs/myenv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/nunorodrigues/miniconda3/envs/myenv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/nunorodrigues/miniconda3/envs/myenv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/nunorodrigues/miniconda3/envs/myenv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/nunorodrigues/miniconda3/envs/myenv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Split data into features and target\n",
    "df = radi.copy()\n",
    "X = df.drop(columns=[\"Transition\"])\n",
    "y = df[\"Transition\"]\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=2025)\n",
    "\n",
    "bagging_params = {\"n_estimators\": [100, 500, 800, 1000]}\n",
    "bagging_model = BaggingClassifier(random_state=2025)\n",
    "bagging_grid = GridSearchCV(bagging_model, bagging_params, scoring='f1_micro', cv=skf, n_jobs=-1)\n",
    "bagging_grid.fit(X_train, y_train)\n",
    "y_pred_bagging = bagging_grid.best_estimator_.predict(X_test)\n",
    "classification_reports[\"Bagging\"] = classification_report(y_test, y_pred_bagging, output_dict=True)\n",
    "print(f\"Best Bagging Model Parameters: {bagging_grid.best_params_}\")\n",
    "print(f\"Bagging Classification Report:\\n\", classification_report(y_test, y_pred_bagging))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18a4150-9b94-4422-b7e4-cf77d7f24380",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18d2b434-43af-4c58-9a20-07296e14e797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RandomForest Model Parameters: {'max_depth': 5, 'n_estimators': 1000}\n",
      "RandomForest Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       AD-AD       0.50      0.36      0.42        14\n",
      "       CN-CN       0.54      0.81      0.65        26\n",
      "      CN-MCI       0.00      0.00      0.00         1\n",
      "      MCI-AD       0.28      0.36      0.31        14\n",
      "     MCI-MCI       0.40      0.18      0.25        22\n",
      "\n",
      "    accuracy                           0.45        77\n",
      "   macro avg       0.34      0.34      0.33        77\n",
      "weighted avg       0.44      0.45      0.42        77\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nunorodrigues/miniconda3/envs/myenv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/nunorodrigues/miniconda3/envs/myenv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/nunorodrigues/miniconda3/envs/myenv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/nunorodrigues/miniconda3/envs/myenv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/nunorodrigues/miniconda3/envs/myenv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/nunorodrigues/miniconda3/envs/myenv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Split data into features and target\n",
    "df = radi.copy()\n",
    "X = df.drop(columns=[\"Transition\"])\n",
    "y = df[\"Transition\"]\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=2025)\n",
    "\n",
    "# Params Definition\n",
    "rf_params = {\"n_estimators\": [100, 500, 800, 1000], \"max_depth\": [5, 10, 20, None]}\n",
    "rf_model = RandomForestClassifier()\n",
    "\n",
    "# model, params, scoring using f1, 5 folds, full processor\n",
    "rf_grid = GridSearchCV(rf_model, rf_params, scoring='f1_micro', cv=skf, n_jobs=-1)\n",
    "rf_grid.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf = rf_grid.best_estimator_.predict(X_test)\n",
    "classification_reports[\"RandomForest\"] = classification_report(y_test, y_pred_rf, output_dict=True)\n",
    "print(f\"Best RandomForest Model Parameters: {rf_grid.best_params_}\")\n",
    "print(f\"RandomForest Classification Report:\\n\", classification_report(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5d9d36-9742-4b63-ab45-4474fb3e6315",
   "metadata": {},
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59c35e6-1870-49f1-a770-a091264f5fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into features and target\n",
    "df = radi.copy()\n",
    "X = df.drop(columns=[\"Transition\"]) \n",
    "y = df[\"Transition\"]\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=2025)\n",
    "\n",
    "# Params Definition\n",
    "gb_params = {\"n_estimators\": [500, 600, 800], \"learning_rate\": [0.1, 0.3, 0.05]}\n",
    "gb_model = GradientBoostingClassifier()\n",
    "\n",
    "# model, params, scoring using f1, 5 folds, full processor\n",
    "gb_grid = GridSearchCV(gb_model, gb_params, scoring='f1_micro',cv=skf, n_jobs=-1)\n",
    "gb_grid.fit(X_train, y_train)\n",
    "\n",
    "y_pred_gb = gb_grid.best_estimator_.predict(X_test)\n",
    "classification_reports[\"GradientBoosting\"] = classification_report(y_test, y_pred_gb, output_dict=True)\n",
    "print(f\"Best GradientBoosting Model Parameters: {gb_grid.best_params_}\")\n",
    "print(f\"GradientBoosting Classification Report:\\n\", classification_report(y_test, y_pred_gb))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2258b027-c232-4e1a-aa3c-2fb834d90ac3",
   "metadata": {},
   "source": [
    "## XGBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1253b0a5-b399-45f0-8784-57923a8b6622",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Copy the dataframe and apply label encoding to the target variable\n",
    "df = radi.copy()\n",
    "label_encoder = LabelEncoder()\n",
    "df['Transition'] = label_encoder.fit_transform(df['Transition'])\n",
    "\n",
    "# Define features and target\n",
    "X = df.drop(columns=[\"Transition\"])\n",
    "y = df[\"Transition\"]\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define XGBoost hyperparameters and model with a multi-class objective and compatible eval_metric\n",
    "xgb_params = {\n",
    "    \"n_estimators\": [500,800,600],\n",
    "    \"learning_rate\": [0.1,0.3],\n",
    "    \"max_depth\": [5,6,8],\n",
    "    \n",
    "}\n",
    "\n",
    "xgb_model = XGBClassifier(eval_metric='mlogloss')\n",
    "\n",
    "# Run GridSearchCV to find the best parameters\n",
    "xgb_grid = GridSearchCV(xgb_model, xgb_params, scoring='f1_micro', cv=skf, n_jobs=-1)\n",
    "xgb_grid.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred_xgb = xgb_grid.best_estimator_.predict(X_test)\n",
    "classification_reports[\"XGBoost\"] = classification_report(y_test, y_pred_xgb, output_dict=True)\n",
    "print(f\"Best XGBoost Model Parameters: {xgb_grid.best_params_}\")\n",
    "print(f\"XGBoost Classification Report:\\n\", classification_report(y_test, y_pred_xgb))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582cf1f4-e743-42b9-822f-b267c01e39ef",
   "metadata": {},
   "source": [
    "## Ver Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31dedfa6-8434-48b1-97ee-1c9720974b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_scores = {model: report[\"weighted avg\"][\"f1-score\"] for model, report in classification_reports.items()}\n",
    "accuracies = {model: report[\"accuracy\"] for model, report in classification_reports.items()}\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# F1 Score Graph\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.bar(f1_scores.keys(), f1_scores.values(), color='skyblue')\n",
    "plt.xlabel(\"Model\")\n",
    "plt.ylabel(\"F1 Score\")\n",
    "plt.title(\"Model Comparison - F1 Scores\")\n",
    "plt.ylim(0, 1)\n",
    "\n",
    "# Accuracy Graph\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.bar(accuracies.keys(), accuracies.values(), color='salmon')\n",
    "plt.xlabel(\"Model\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Model Comparison - Accuracy\")\n",
    "plt.ylim(0, 1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46ee5db-1e29-4bf6-a633-c1aa353eaffc",
   "metadata": {},
   "source": [
    "## Generating csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f5ef06f-d585-4137-9c63-098fde399089",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Load the test dataset\n",
    "test_data = pd.read_csv(\"sbsppdaa24/test_radiomics_hipocamp.csv\")\n",
    "\n",
    "# Apply the same preprocessing as in the training phase\n",
    "# Drop unique identifier columns\n",
    "test_data.drop(columns=[\"Mask\", \"ID\", \"Image\"], inplace=True)\n",
    "\n",
    "# Ensure 'columns_to_drop' is available for test data\n",
    "# If you haven't redefined this variable, you need to redo this step for the test set.\n",
    "# Use the same method to identify non-numeric columns for dropping\n",
    "non_numeric_columns = [col for col in test_data.columns if test_data[col].dtype == 'object']\n",
    "test_data.drop(columns=non_numeric_columns, inplace=True)\n",
    "\n",
    "# Apply the same MinMaxScaler that was fit on the training data\n",
    "test_data[float_cols] = scaler.transform(test_data[float_cols])  # Correctly reference columns in test_data\n",
    "\n",
    "# Generate predictions using the RandomForest model\n",
    "bg_predictions_test = bagging_grid.predict(test_data)\n",
    "\n",
    "# Generate predictions using the RandomForest model\n",
    "rf_predictions_test = rf_grid.predict(test_data)\n",
    "\n",
    "\n",
    "res0 = pd.DataFrame({\n",
    "    'RowId': range(1, len(bg_predictions_test) + 1),\n",
    "    'Result': bg_predictions_test \n",
    "})\n",
    "\n",
    "\n",
    "# Store the results in a DataFrame and save to CSV\n",
    "res1 = pd.DataFrame({\n",
    "    'RowId': range(1, len(rf_predictions_test) + 1),\n",
    "    'Result': rf_predictions_test\n",
    "})\n",
    "\n",
    "# Save predictions to a CSV file\n",
    "res0.to_csv('BagginGrid1.0.csv', index=False)\n",
    "res1.to_csv('RandomForestGrid1.0.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3748da0e-e79f-46ee-b9e1-4e483d5efb7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
